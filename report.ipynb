{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Vehicle Detection\n",
    "\n",
    "In this project I'll write a software pipeline to detect vehicles in a video.\n",
    "\n",
    "## Goals of Project\n",
    "\n",
    "* Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier\n",
    "* Optionally, you can also apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector. \n",
    "* Note: for those first two steps don't forget to normalize your features and randomize a selection for training and testing.\n",
    "* Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "* Run your pipeline on a video stream (start with the test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n",
    "* Estimate a bounding box for vehicles detected.\n",
    "\n",
    "# Data Exploration\n",
    "\n",
    "There are two videos given first one `test_video.mp4` which can be used to test pipeline. Second one `project_video.mp4` is the video on which will be evaluated and pipeline should be able to detect vehicles reliably on that video.\n",
    "\n",
    "Training images are split into **vehicle** and **non-vehicle** classes.\n",
    "\n",
    "<figure>\n",
    " <img src=\"./illustrations/vehicle_01.png\" width=\"64\" alt=\"Vehicle 01\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Example of Vehicle</p> \n",
    " </figcaption>\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    " <img src=\"./illustrations/vehicle_02.png\" width=\"64\" alt=\"Vehicle 02\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Example of Another Vehicle</p> \n",
    " </figcaption>\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    " <img src=\"./illustrations/non_vehicle_01.png\" width=\"64\" alt=\"Non Vehicle 01\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Example of Non Vehicle</p> \n",
    " </figcaption>\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    " <img src=\"./illustrations/non_vehicle_02.png\" width=\"64\" alt=\"Non Vehicle 02\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Example of Another Non Vehicle</p> \n",
    " </figcaption>\n",
    "</figure>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "I have created a helpful script which downloads data from internet and unpacks it into `./data` directory\n",
    "\n",
    "Next we need a way to load training images in python. My plan is to create 2 functions for loading training data. First one loads small subset of data and the second one loads the full set. Both of those functions should return data in same format and in this case let's define that the format should be **uint8 BGR** which is easy to use with OpenCV2.\n",
    "\n",
    "in `dataset.py` i have created 2 functions `load_small()` and `load_full()` which are loading the small and full datasets respectively.\n",
    "Those functions return features and labels and in this case feature is array of (N, 64, 64, 3) where **N** denotes the number of images. labels are simply **number 0 for non-vehicles** and **number 1 for vehicles**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics\n",
    "\n",
    "Let's briefly check quantity, shape and type of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small data set:\n\tNumber of vehicle images = 1196\n\tNumber of non-vehicle images = 1125\n\tShape of the image is  (64, 64, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\nFull data set:\n\tNumber of vehicle images = 8792\n\tNumber of non-vehicle images = 8968\n\tShape of the image is  (64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "import dataset\n",
    "\n",
    "dataset.print_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lauri/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from dataset import *\n",
    "\n",
    "# Define a function to compute binned color features  \n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "X, y = load_small()\n",
    "\n",
    "features = []\n",
    "for x in X:\n",
    "    feat = bin_spatial((32,32))\n",
    "    features.append(feat)\n",
    "\n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(features)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}